{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maximilianovedoya-coder/VibeVoice/blob/main/demo/vibevoice_realtime_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WvIaUJD2y0yU",
      "metadata": {
        "id": "WvIaUJD2y0yU"
      },
      "source": [
        "# VibeVoice-Realtime Colab — T4 Quickstart\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8fTKYGx7DZk",
      "metadata": {
        "id": "e8fTKYGx7DZk"
      },
      "source": [
        "## Step 1: Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4wxJ6QHM-ZOb",
      "metadata": {
        "id": "4wxJ6QHM-ZOb"
      },
      "outputs": [],
      "source": [
        "# Check for T4 GPU\n",
        "import torch\n",
        "if torch.cuda.is_available() and \"T4\" in torch.cuda.get_device_name(0):\n",
        "    print(\"✅ T4 GPU detected\")\n",
        "else:\n",
        "    print(\"\"\"\n",
        "    ⚠️ WARNING: T4 GPU not detected\n",
        "\n",
        "    The recommended runtime for this Colab notebook is \"T4 GPU\".\n",
        "\n",
        "    To change the runtime type:\n",
        "\n",
        "        1. Click on \"Runtime\" in the top navigation menu\n",
        "        2. Click on \"Change runtime type\"\n",
        "        3. Select \"T4 GPU\"\n",
        "        4. Click \"OK\" if a \"Disconnect and delete runtime\" window appears\n",
        "        5. Click on \"Save\"\n",
        "\n",
        "    \"\"\")\n",
        "\n",
        "# Clone the VibeVoice repository\n",
        "![ -d /content/VibeVoice ] || git clone --quiet --branch main --depth 1 https://github.com/microsoft/VibeVoice.git /content/VibeVoice\n",
        "print(\"✅ Cloned VibeVoice repository\")\n",
        "\n",
        "# Install project dependencies\n",
        "!uv pip --quiet install --system -e /content/VibeVoice\n",
        "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O cloudflared && chmod +x cloudflared\n",
        "print(\"✅ Installed dependencies\")\n",
        "\n",
        "# Download model\n",
        "from huggingface_hub import snapshot_download\n",
        "snapshot_download(\"microsoft/VibeVoice-Realtime-0.5B\", local_dir=\"/content/models/VibeVoice-Realtime-0.5B\")\n",
        "print(\"✅ Downloaded model: microsoft/VibeVoice-Realtime-0.5B\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88c727ab",
      "metadata": {
        "id": "88c727ab"
      },
      "source": [
        "[Optional] If the download exceeds 1 minute, it is probably stuck. You can: (1) interrupt the execution, (2) log in to Hugging Face, and (3) try download again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dec6b870",
      "metadata": {
        "id": "dec6b870"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c579654b",
      "metadata": {
        "id": "c579654b"
      },
      "outputs": [],
      "source": [
        "snapshot_download(\"microsoft/VibeVoice-Realtime-0.5B\", local_dir=\"/content/models/VibeVoice-Realtime-0.5B\")\n",
        "print(\"✅ Downloaded model: microsoft/VibeVoice-Realtime-0.5B\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfe30d6f",
      "metadata": {
        "id": "dfe30d6f"
      },
      "source": [
        "[Optional] More experimental voices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb33c9ce",
      "metadata": {
        "id": "bb33c9ce"
      },
      "outputs": [],
      "source": [
        "!bash /content/VibeVoice/demo/download_experimental_voices.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pgKlV7153Ifi",
      "metadata": {
        "id": "pgKlV7153Ifi"
      },
      "source": [
        "## Step 2: Launch VibeVoice-Realtime Demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Yc1N9EHswFxA",
      "metadata": {
        "id": "Yc1N9EHswFxA",
        "outputId": "11812a99-d9e8-497a-ac4e-e49476216b5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-01-14 22:14:21.061185: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768428861.306410    1021 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768428861.373246    1021 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768428861.876450    1021 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768428861.876482    1021 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768428861.876486    1021 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768428861.876488    1021 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-14 22:14:21.924603: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "WARNING:vibevoice.modular.modular_vibevoice_tokenizer:APEX FusedRMSNorm not available, using native implementation\n",
            "INFO:     Started server process [1021]\n",
            "INFO:     Waiting for application startup.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization.\n",
            "The tokenizer class you load from this checkpoint is 'Qwen2Tokenizer'.\n",
            "The class this function is called from is 'VibeVoiceTextTokenizerFast'.\n",
            "You are using a model of type vibevoice to instantiate a model of type vibevoice_streaming. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type vibevoice to instantiate a model of type vibevoice_streaming. This is not supported for all configurations of models and can yield errors.\n",
            "[startup] Loading processor from /content/models/VibeVoice-1.5B\n",
            "Using device: cuda, torch_dtype: torch.bfloat16, attn_implementation: flash_attention_2\n",
            "Error loading the model. Trying to use SDPA. However, note that only flash_attention_2 has been fully tested, and using SDPA may result in lower audio quality.\n",
            "\n",
            "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]\n",
            "Loading checkpoint shards:  33%|███▎      | 1/3 [00:03<00:06,  3.47s/it]\n",
            "Loading checkpoint shards:  67%|██████▋   | 2/3 [00:04<00:01,  1.83s/it]\n",
            "Loading checkpoint shards: 100%|██████████| 3/3 [00:07<00:00,  2.42s/it]\n",
            "Loading checkpoint shards: 100%|██████████| 3/3 [00:07<00:00,  2.42s/it]\n",
            "Some weights of VibeVoiceStreamingForConditionalGenerationInference were not initialized from the model checkpoint at /content/models/VibeVoice-1.5B and are newly initialized: ['model.tts_input_types.weight', 'model.tts_language_model.embed_tokens.weight', 'model.tts_language_model.layers.0.input_layernorm.weight', 'model.tts_language_model.layers.0.mlp.down_proj.weight', 'model.tts_language_model.layers.0.mlp.gate_proj.weight', 'model.tts_language_model.layers.0.mlp.up_proj.weight', 'model.tts_language_model.layers.0.post_attention_layernorm.weight', 'model.tts_language_model.layers.0.self_attn.k_proj.bias', 'model.tts_language_model.layers.0.self_attn.k_proj.weight', 'model.tts_language_model.layers.0.self_attn.o_proj.weight', 'model.tts_language_model.layers.0.self_attn.q_proj.bias', 'model.tts_language_model.layers.0.self_attn.q_proj.weight', 'model.tts_language_model.layers.0.self_attn.v_proj.bias', 'model.tts_language_model.layers.0.self_attn.v_proj.weight', 'model.tts_language_model.layers.1.input_layernorm.weight', 'model.tts_language_model.layers.1.mlp.down_proj.weight', 'model.tts_language_model.layers.1.mlp.gate_proj.weight', 'model.tts_language_model.layers.1.mlp.up_proj.weight', 'model.tts_language_model.layers.1.post_attention_layernorm.weight', 'model.tts_language_model.layers.1.self_attn.k_proj.bias', 'model.tts_language_model.layers.1.self_attn.k_proj.weight', 'model.tts_language_model.layers.1.self_attn.o_proj.weight', 'model.tts_language_model.layers.1.self_attn.q_proj.bias', 'model.tts_language_model.layers.1.self_attn.q_proj.weight', 'model.tts_language_model.layers.1.self_attn.v_proj.bias', 'model.tts_language_model.layers.1.self_attn.v_proj.weight', 'model.tts_language_model.layers.10.input_layernorm.weight', 'model.tts_language_model.layers.10.mlp.down_proj.weight', 'model.tts_language_model.layers.10.mlp.gate_proj.weight', 'model.tts_language_model.layers.10.mlp.up_proj.weight', 'model.tts_language_model.layers.10.post_attention_layernorm.weight', 'model.tts_language_model.layers.10.self_attn.k_proj.bias', 'model.tts_language_model.layers.10.self_attn.k_proj.weight', 'model.tts_language_model.layers.10.self_attn.o_proj.weight', 'model.tts_language_model.layers.10.self_attn.q_proj.bias', 'model.tts_language_model.layers.10.self_attn.q_proj.weight', 'model.tts_language_model.layers.10.self_attn.v_proj.bias', 'model.tts_language_model.layers.10.self_attn.v_proj.weight', 'model.tts_language_model.layers.11.input_layernorm.weight', 'model.tts_language_model.layers.11.mlp.down_proj.weight', 'model.tts_language_model.layers.11.mlp.gate_proj.weight', 'model.tts_language_model.layers.11.mlp.up_proj.weight', 'model.tts_language_model.layers.11.post_attention_layernorm.weight', 'model.tts_language_model.layers.11.self_attn.k_proj.bias', 'model.tts_language_model.layers.11.self_attn.k_proj.weight', 'model.tts_language_model.layers.11.self_attn.o_proj.weight', 'model.tts_language_model.layers.11.self_attn.q_proj.bias', 'model.tts_language_model.layers.11.self_attn.q_proj.weight', 'model.tts_language_model.layers.11.self_attn.v_proj.bias', 'model.tts_language_model.layers.11.self_attn.v_proj.weight', 'model.tts_language_model.layers.12.input_layernorm.weight', 'model.tts_language_model.layers.12.mlp.down_proj.weight', 'model.tts_language_model.layers.12.mlp.gate_proj.weight', 'model.tts_language_model.layers.12.mlp.up_proj.weight', 'model.tts_language_model.layers.12.post_attention_layernorm.weight', 'model.tts_language_model.layers.12.self_attn.k_proj.bias', 'model.tts_language_model.layers.12.self_attn.k_proj.weight', 'model.tts_language_model.layers.12.self_attn.o_proj.weight', 'model.tts_language_model.layers.12.self_attn.q_proj.bias', 'model.tts_language_model.layers.12.self_attn.q_proj.weight', 'model.tts_language_model.layers.12.self_attn.v_proj.bias', 'model.tts_language_model.layers.12.self_attn.v_proj.weight', 'model.tts_language_model.layers.13.input_layernorm.weight', 'model.tts_language_model.layers.13.mlp.down_proj.weight', 'model.tts_language_model.layers.13.mlp.gate_proj.weight', 'model.tts_language_model.layers.13.mlp.up_proj.weight', 'model.tts_language_model.layers.13.post_attention_layernorm.weight', 'model.tts_language_model.layers.13.self_attn.k_proj.bias', 'model.tts_language_model.layers.13.self_attn.k_proj.weight', 'model.tts_language_model.layers.13.self_attn.o_proj.weight', 'model.tts_language_model.layers.13.self_attn.q_proj.bias', 'model.tts_language_model.layers.13.self_attn.q_proj.weight', 'model.tts_language_model.layers.13.self_attn.v_proj.bias', 'model.tts_language_model.layers.13.self_attn.v_proj.weight', 'model.tts_language_model.layers.14.input_layernorm.weight', 'model.tts_language_model.layers.14.mlp.down_proj.weight', 'model.tts_language_model.layers.14.mlp.gate_proj.weight', 'model.tts_language_model.layers.14.mlp.up_proj.weight', 'model.tts_language_model.layers.14.post_attention_layernorm.weight', 'model.tts_language_model.layers.14.self_attn.k_proj.bias', 'model.tts_language_model.layers.14.self_attn.k_proj.weight', 'model.tts_language_model.layers.14.self_attn.o_proj.weight', 'model.tts_language_model.layers.14.self_attn.q_proj.bias', 'model.tts_language_model.layers.14.self_attn.q_proj.weight', 'model.tts_language_model.layers.14.self_attn.v_proj.bias', 'model.tts_language_model.layers.14.self_attn.v_proj.weight', 'model.tts_language_model.layers.15.input_layernorm.weight', 'model.tts_language_model.layers.15.mlp.down_proj.weight', 'model.tts_language_model.layers.15.mlp.gate_proj.weight', 'model.tts_language_model.layers.15.mlp.up_proj.weight', 'model.tts_language_model.layers.15.post_attention_layernorm.weight', 'model.tts_language_model.layers.15.self_attn.k_proj.bias', 'model.tts_language_model.layers.15.self_attn.k_proj.weight', 'model.tts_language_model.layers.15.self_attn.o_proj.weight', 'model.tts_language_model.layers.15.self_attn.q_proj.bias', 'model.tts_language_model.layers.15.self_attn.q_proj.weight', 'model.tts_language_model.layers.15.self_attn.v_proj.bias', 'model.tts_language_model.layers.15.self_attn.v_proj.weight', 'model.tts_language_model.layers.16.input_layernorm.weight', 'model.tts_language_model.layers.16.mlp.down_proj.weight', 'model.tts_language_model.layers.16.mlp.gate_proj.weight', 'model.tts_language_model.layers.16.mlp.up_proj.weight', 'model.tts_language_model.layers.16.post_attention_layernorm.weight', 'model.tts_language_model.layers.16.self_attn.k_proj.bias', 'model.tts_language_model.layers.16.self_attn.k_proj.weight', 'model.tts_language_model.layers.16.self_attn.o_proj.weight', 'model.tts_language_model.layers.16.self_attn.q_proj.bias', 'model.tts_language_model.layers.16.self_attn.q_proj.weight', 'model.tts_language_model.layers.16.self_attn.v_proj.bias', 'model.tts_language_model.layers.16.self_attn.v_proj.weight', 'model.tts_language_model.layers.17.input_layernorm.weight', 'model.tts_language_model.layers.17.mlp.down_proj.weight', 'model.tts_language_model.layers.17.mlp.gate_proj.weight', 'model.tts_language_model.layers.17.mlp.up_proj.weight', 'model.tts_language_model.layers.17.post_attention_layernorm.weight', 'model.tts_language_model.layers.17.self_attn.k_proj.bias', 'model.tts_language_model.layers.17.self_attn.k_proj.weight', 'model.tts_language_model.layers.17.self_attn.o_proj.weight', 'model.tts_language_model.layers.17.self_attn.q_proj.bias', 'model.tts_language_model.layers.17.self_attn.q_proj.weight', 'model.tts_language_model.layers.17.self_attn.v_proj.bias', 'model.tts_language_model.layers.17.self_attn.v_proj.weight', 'model.tts_language_model.layers.18.input_layernorm.weight', 'model.tts_language_model.layers.18.mlp.down_proj.weight', 'model.tts_language_model.layers.18.mlp.gate_proj.weight', 'model.tts_language_model.layers.18.mlp.up_proj.weight', 'model.tts_language_model.layers.18.post_attention_layernorm.weight', 'model.tts_language_model.layers.18.self_attn.k_proj.bias', 'model.tts_language_model.layers.18.self_attn.k_proj.weight', 'model.tts_language_model.layers.18.self_attn.o_proj.weight', 'model.tts_language_model.layers.18.self_attn.q_proj.bias', 'model.tts_language_model.layers.18.self_attn.q_proj.weight', 'model.tts_language_model.layers.18.self_attn.v_proj.bias', 'model.tts_language_model.layers.18.self_attn.v_proj.weight', 'model.tts_language_model.layers.19.input_layernorm.weight', 'model.tts_language_model.layers.19.mlp.down_proj.weight', 'model.tts_language_model.layers.19.mlp.gate_proj.weight', 'model.tts_language_model.layers.19.mlp.up_proj.weight', 'model.tts_language_model.layers.19.post_attention_layernorm.weight', 'model.tts_language_model.layers.19.self_attn.k_proj.bias', 'model.tts_language_model.layers.19.self_attn.k_proj.weight', 'model.tts_language_model.layers.19.self_attn.o_proj.weight', 'model.tts_language_model.layers.19.self_attn.q_proj.bias', 'model.tts_language_model.layers.19.self_attn.q_proj.weight', 'model.tts_language_model.layers.19.self_attn.v_proj.bias', 'model.tts_language_model.layers.19.self_attn.v_proj.weight', 'model.tts_language_model.layers.2.input_layernorm.weight', 'model.tts_language_model.layers.2.mlp.down_proj.weight', 'model.tts_language_model.layers.2.mlp.gate_proj.weight', 'model.tts_language_model.layers.2.mlp.up_proj.weight', 'model.tts_language_model.layers.2.post_attention_layernorm.weight', 'model.tts_language_model.layers.2.self_attn.k_proj.bias', 'model.tts_language_model.layers.2.self_attn.k_proj.weight', 'model.tts_language_model.layers.2.self_attn.o_proj.weight', 'model.tts_language_model.layers.2.self_attn.q_proj.bias', 'model.tts_language_model.layers.2.self_attn.q_proj.weight', 'model.tts_language_model.layers.2.self_attn.v_proj.bias', 'model.tts_language_model.layers.2.self_attn.v_proj.weight', 'model.tts_language_model.layers.3.input_layernorm.weight', 'model.tts_language_model.layers.3.mlp.down_proj.weight', 'model.tts_language_model.layers.3.mlp.gate_proj.weight', 'model.tts_language_model.layers.3.mlp.up_proj.weight', 'model.tts_language_model.layers.3.post_attention_layernorm.weight', 'model.tts_language_model.layers.3.self_attn.k_proj.bias', 'model.tts_language_model.layers.3.self_attn.k_proj.weight', 'model.tts_language_model.layers.3.self_attn.o_proj.weight', 'model.tts_language_model.layers.3.self_attn.q_proj.bias', 'model.tts_language_model.layers.3.self_attn.q_proj.weight', 'model.tts_language_model.layers.3.self_attn.v_proj.bias', 'model.tts_language_model.layers.3.self_attn.v_proj.weight', 'model.tts_language_model.layers.4.input_layernorm.weight', 'model.tts_language_model.layers.4.mlp.down_proj.weight', 'model.tts_language_model.layers.4.mlp.gate_proj.weight', 'model.tts_language_model.layers.4.mlp.up_proj.weight', 'model.tts_language_model.layers.4.post_attention_layernorm.weight', 'model.tts_language_model.layers.4.self_attn.k_proj.bias', 'model.tts_language_model.layers.4.self_attn.k_proj.weight', 'model.tts_language_model.layers.4.self_attn.o_proj.weight', 'model.tts_language_model.layers.4.self_attn.q_proj.bias', 'model.tts_language_model.layers.4.self_attn.q_proj.weight', 'model.tts_language_model.layers.4.self_attn.v_proj.bias', 'model.tts_language_model.layers.4.self_attn.v_proj.weight', 'model.tts_language_model.layers.5.input_layernorm.weight', 'model.tts_language_model.layers.5.mlp.down_proj.weight', 'model.tts_language_model.layers.5.mlp.gate_proj.weight', 'model.tts_language_model.layers.5.mlp.up_proj.weight', 'model.tts_language_model.layers.5.post_attention_layernorm.weight', 'model.tts_language_model.layers.5.self_attn.k_proj.bias', 'model.tts_language_model.layers.5.self_attn.k_proj.weight', 'model.tts_language_model.layers.5.self_attn.o_proj.weight', 'model.tts_language_model.layers.5.self_attn.q_proj.bias', 'model.tts_language_model.layers.5.self_attn.q_proj.weight', 'model.tts_language_model.layers.5.self_attn.v_proj.bias', 'model.tts_language_model.layers.5.self_attn.v_proj.weight', 'model.tts_language_model.layers.6.input_layernorm.weight', 'model.tts_language_model.layers.6.mlp.down_proj.weight', 'model.tts_language_model.layers.6.mlp.gate_proj.weight', 'model.tts_language_model.layers.6.mlp.up_proj.weight', 'model.tts_language_model.layers.6.post_attention_layernorm.weight', 'model.tts_language_model.layers.6.self_attn.k_proj.bias', 'model.tts_language_model.layers.6.self_attn.k_proj.weight', 'model.tts_language_model.layers.6.self_attn.o_proj.weight', 'model.tts_language_model.layers.6.self_attn.q_proj.bias', 'model.tts_language_model.layers.6.self_attn.q_proj.weight', 'model.tts_language_model.layers.6.self_attn.v_proj.bias', 'model.tts_language_model.layers.6.self_attn.v_proj.weight', 'model.tts_language_model.layers.7.input_layernorm.weight', 'model.tts_language_model.layers.7.mlp.down_proj.weight', 'model.tts_language_model.layers.7.mlp.gate_proj.weight', 'model.tts_language_model.layers.7.mlp.up_proj.weight', 'model.tts_language_model.layers.7.post_attention_layernorm.weight', 'model.tts_language_model.layers.7.self_attn.k_proj.bias', 'model.tts_language_model.layers.7.self_attn.k_proj.weight', 'model.tts_language_model.layers.7.self_attn.o_proj.weight', 'model.tts_language_model.layers.7.self_attn.q_proj.bias', 'model.tts_language_model.layers.7.self_attn.q_proj.weight', 'model.tts_language_model.layers.7.self_attn.v_proj.bias', 'model.tts_language_model.layers.7.self_attn.v_proj.weight', 'model.tts_language_model.layers.8.input_layernorm.weight', 'model.tts_language_model.layers.8.mlp.down_proj.weight', 'model.tts_language_model.layers.8.mlp.gate_proj.weight', 'model.tts_language_model.layers.8.mlp.up_proj.weight', 'model.tts_language_model.layers.8.post_attention_layernorm.weight', 'model.tts_language_model.layers.8.self_attn.k_proj.bias', 'model.tts_language_model.layers.8.self_attn.k_proj.weight', 'model.tts_language_model.layers.8.self_attn.o_proj.weight', 'model.tts_language_model.layers.8.self_attn.q_proj.bias', 'model.tts_language_model.layers.8.self_attn.q_proj.weight', 'model.tts_language_model.layers.8.self_attn.v_proj.bias', 'model.tts_language_model.layers.8.self_attn.v_proj.weight', 'model.tts_language_model.layers.9.input_layernorm.weight', 'model.tts_language_model.layers.9.mlp.down_proj.weight', 'model.tts_language_model.layers.9.mlp.gate_proj.weight', 'model.tts_language_model.layers.9.mlp.up_proj.weight', 'model.tts_language_model.layers.9.post_attention_layernorm.weight', 'model.tts_language_model.layers.9.self_attn.k_proj.bias', 'model.tts_language_model.layers.9.self_attn.k_proj.weight', 'model.tts_language_model.layers.9.self_attn.o_proj.weight', 'model.tts_language_model.layers.9.self_attn.q_proj.bias', 'model.tts_language_model.layers.9.self_attn.q_proj.weight', 'model.tts_language_model.layers.9.self_attn.v_proj.bias', 'model.tts_language_model.layers.9.self_attn.v_proj.weight', 'model.tts_language_model.norm.weight', 'tts_eos_classifier.fc1.bias', 'tts_eos_classifier.fc1.weight', 'tts_eos_classifier.fc2.bias', 'tts_eos_classifier.fc2.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n",
            "✅ Public URL: https://early-seeks-department-committee.trycloudflare.com\n",
            "\n",
            "Load model with SDPA successfully\n",
            "[startup] Found 61 voice presets\n",
            "[startup] Using fallback voice preset: de-Spk0_man\n",
            "[startup] Loading voice preset de-Spk0_man from /content/VibeVoice/demo/voices/streaming_model/de-Spk0_man.pt\n",
            "[startup] Loading prefilled prompt from /content/VibeVoice/demo/voices/streaming_model/de-Spk0_man.pt\n",
            "[startup] Model ready.\n",
            "INFO:     2600:1700:5120:27f0:305a:fed6:646f:e2f1:0 - \"GET / HTTP/1.1\" 200 OK\n",
            "INFO:     2600:1700:5120:27f0:305a:fed6:646f:e2f1:0 - \"GET /favicon.ico HTTP/1.1\" 404 Not Found\n",
            "INFO:     2600:1700:5120:27f0:305a:fed6:646f:e2f1:0 - \"GET /config HTTP/1.1\" 200 OK\n",
            "INFO:     connection rejected (400 Bad Request)\n",
            "INFO:     connection closed\n"
          ]
        }
      ],
      "source": [
        "import subprocess, re, time, threading\n",
        "\n",
        "srv = subprocess.Popen(\n",
        "    \"python /content/VibeVoice/demo/vibevoice_realtime_demo.py --model_path /content/models/VibeVoice-Realtime-0.5B --port 8000\",\n",
        "    shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1, universal_newlines=True,\n",
        ")\n",
        "cf = subprocess.Popen(\n",
        "    \"./cloudflared tunnel --url http://localhost:8000 --no-autoupdate\",\n",
        "    shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1, universal_newlines=True,\n",
        ")\n",
        "\n",
        "public_url = None\n",
        "server_ready = False\n",
        "url_pattern  = re.compile(r\"(https://[a-z0-9-]+\\.trycloudflare\\.com)\")\n",
        "\n",
        "def read_srv():\n",
        "    global server_ready\n",
        "    for ln in srv.stdout:\n",
        "        print(ln.strip())\n",
        "        if \"Uvicorn running on\" in ln:\n",
        "            server_ready = True\n",
        "\n",
        "def read_cf():\n",
        "    global public_url\n",
        "    for ln in cf.stdout:\n",
        "        m = url_pattern.search(ln)\n",
        "        if m:\n",
        "            public_url = m.group(1)\n",
        "            break\n",
        "\n",
        "threading.Thread(target=read_srv, daemon=True).start()\n",
        "threading.Thread(target=read_cf,  daemon=True).start()\n",
        "\n",
        "\n",
        "while True:\n",
        "    if server_ready and public_url:\n",
        "        print(f\"✅ Public URL: {public_url}\\n\");\n",
        "        public_url = None\n",
        "    time.sleep(0.25)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "name": "VibeVoice_Colab.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}